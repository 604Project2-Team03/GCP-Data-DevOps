{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06483855-a622-4a5c-b1e3-524f073dd39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import time\n",
    "import traceback\n",
    "\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options import pipeline_options\n",
    "from apache_beam.io.gcp.pubsub import ReadFromPubSub\n",
    "from apache_beam.io.gcp.bigquery import BigQueryDisposition, WriteToBigQuery\n",
    "from apache_beam.io import WriteToText\n",
    "\n",
    "from apache_beam import (\n",
    "    DoFn, \n",
    "    io,\n",
    "    ParDo, \n",
    "    PTransform,\n",
    "    WindowInto, \n",
    "    WithKeys,\n",
    ")\n",
    "\n",
    "from apache_beam.runners import DataflowRunner\n",
    "import csv\n",
    "import google.auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a39f6eb-a5f0-4bd9-8846-2e1905e463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_auth = google.auth.default()[1] \n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pipeline_options = pipeline_options.PipelineOptions(\n",
    "    flags = {},\n",
    "    project = project_auth, \n",
    "    region= 'us-central1', \n",
    "    staging_location = \"%s/staging\" % \"data604-project-g3-data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "738eed3a-6e5c-442f-b3b2-8d0a6234b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_schema = { \n",
    "    \"fields\":[ \n",
    "        {'name': \"user_id\", 'type':\"STRING\", 'mode':\"NULLABLE\"}, \n",
    "        {'name': \"phone_number\", 'type':\"STRING\", 'mode':\"NULLABLE\"}, \n",
    "        {'name': \"incoming\",'type': \"BOOLEAN\", 'mode':\"NULLABLE\"},\n",
    "        {\"name\": \"registered\", \"type\": \"BOOLEAN\", \"mode\": \"NULLABLE\"},\n",
    "        {'name': \"count\" , 'type' : \"INTEGER\" , 'mode' : 'NULLABLE'}\n",
    "    ]\n",
    "}\n",
    "table = \"data604-project-g3:Footprint_data.calls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "723ccd99-a31f-4a4d-8deb-3c13bd4768ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.gcp.gcsio:Unexpected error occurred when checking soft delete policy for gs://dataflow-staging-us-central1-18675e2485afe7315f18de97c3880eff\n",
      "WARNING:apache_beam.io.gcp.gcsio:Unexpected error occurred when checking soft delete policy for gs://dataflow-staging-us-central1-18675e2485afe7315f18de97c3880eff\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    div.alert {\n",
       "      white-space: pre-line;\n",
       "    }\n",
       "  </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\">\n",
       "            <div class=\"alert alert-info\">No cache_root detected. Defaulting to staging_location gs://dataflow-staging-us-central1-18675e2485afe7315f18de97c3880eff for cache location.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_file_loads.UpdateDestinationSchema'>)\n",
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_file_loads.TriggerCopyJobs'>)\n",
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_file_loads.DeleteTablesFn'>)\n",
      "WARNING:apache_beam.io.gcp.gcsio:Unexpected error occurred when checking soft delete policy for gs://dataflow-staging-us-central1-18675e2485afe7315f18de97c3880eff\n",
      "WARNING:apache_beam.io.gcp.gcsio:Unexpected error occurred when checking soft delete policy for gs://dataflow-staging-us-central1-18675e2485afe7315f18de97c3880eff\n",
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_file_loads.UpdateDestinationSchema'>)\n",
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_file_loads.TriggerCopyJobs'>)\n",
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_file_loads.DeleteTablesFn'>)\n",
      "\u001b[33mWARNING: The directory '/home/jupyter/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO:apache_beam.runners.dataflow.dataflow_runner:Pipeline has additional dependencies to be installed in SDK worker container, consider using the SDK container image pre-building workflow to avoid repetitive installations. Learn more on https://cloud.google.com/dataflow/docs/guides/using-custom-containers#prebuild\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://dataflow-staging-us-central1-18675e2485afe7315f18de97c3880eff/beamapp-root-1127230020-915980-p7pejyxo.1732748420.916173/submission_environment_dependencies.txt...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://dataflow-staging-us-central1-18675e2485afe7315f18de97c3880eff/beamapp-root-1127230020-915980-p7pejyxo.1732748420.916173/submission_environment_dependencies.txt in 0 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://dataflow-staging-us-central1-18675e2485afe7315f18de97c3880eff/beamapp-root-1127230020-915980-p7pejyxo.1732748420.916173/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://dataflow-staging-us-central1-18675e2485afe7315f18de97c3880eff/beamapp-root-1127230020-915980-p7pejyxo.1732748420.916173/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " clientRequestId: '20241127230020917062-9738'\n",
      " createTime: '2024-11-27T23:00:21.527581Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2024-11-27_15_00_21-2354144757739365416'\n",
      " location: 'us-central1'\n",
      " name: 'beamapp-root-1127230020-915980-p7pejyxo'\n",
      " projectId: 'data604-project-g3'\n",
      " stageStates: []\n",
      " startTime: '2024-11-27T23:00:21.527581Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2024-11-27_15_00_21-2354144757739365416]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Submitted job: 2024-11-27_15_00_21-2354144757739365416\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobs/us-central1/2024-11-27_15_00_21-2354144757739365416?project=data604-project-g3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DataflowPipelineResult <Job\n",
       " clientRequestId: '20241127230020917062-9738'\n",
       " createTime: '2024-11-27T23:00:21.527581Z'\n",
       " currentStateTime: '1970-01-01T00:00:00Z'\n",
       " id: '2024-11-27_15_00_21-2354144757739365416'\n",
       " location: 'us-central1'\n",
       " name: 'beamapp-root-1127230020-915980-p7pejyxo'\n",
       " projectId: 'data604-project-g3'\n",
       " stageStates: []\n",
       " startTime: '2024-11-27T23:00:21.527581Z'\n",
       " steps: []\n",
       " tempFiles: []\n",
       " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)> at 0x7fdf2498a7a0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def define_key(element):\n",
    "    import json\n",
    "    del element['time']\n",
    "    return (json.dumps(element), element)\n",
    "\n",
    "def expand(element):\n",
    "    import json\n",
    "    key, value = element\n",
    "    dictionary = json.loads(key)\n",
    "    dictionary['count'] = value\n",
    "    return dictionary\n",
    "\n",
    "def parse_csv(line):\n",
    "    import csv\n",
    "    return next(csv.reader([line]))\n",
    "\n",
    "call_data_p = beam.Pipeline(DataflowRunner(), options = pipeline_options)\n",
    "\n",
    "call_data = (call_data_p | \"Read\" >> beam.io.ReadFromText('gs://data604-project-g3-data/calls.json')\n",
    "                         | \"Parse JSON\" >> beam.Map(json.loads) \n",
    "                         | \"Define_Key\" >> beam.Map(define_key)\n",
    "                         | 'Count elements per key' >> beam.combiners.Count.PerKey()\n",
    "                         | 'Turn key back to content' >> beam.Map(expand)\n",
    "            )\n",
    "\n",
    "\n",
    "call_data | \"Write To BigQuery\" >> WriteToBigQuery(table=table, schema=table_schema,\n",
    "                                  create_disposition=BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "                                  write_disposition=BigQueryDisposition.WRITE_TRUNCATE)\n",
    "\n",
    "\n",
    "call_data_p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ab96430-efd8-483b-8257-aca45314cf15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_file_loads.UpdateDestinationSchema'>)\n",
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_file_loads.TriggerCopyJobs'>)\n",
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_file_loads.DeleteTablesFn'>)\n",
      "INFO:apache_beam.runners.worker.statecache:Creating state cache with size 104857600\n",
      "INFO:apache_beam.io.gcp.bigquery_file_loads:Load job has 1 files. Job name is beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_ebdf7a9f317345dd9af236a2dc818441_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0.\n",
      "INFO:apache_beam.io.gcp.bigquery_file_loads:Triggering job beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_ebdf7a9f317345dd9af236a2dc818441_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0 to load data to BigQuery table <TableReference\n",
      " datasetId: 'Footprint_data'\n",
      " projectId: 'data604-project-g3'\n",
      " tableId: 'calls'>.Schema: {'fields': [{'name': 'user_id', 'type': 'STRING', 'mode': 'NULLABLE'}, {'name': 'phone_number', 'type': 'STRING', 'mode': 'NULLABLE'}, {'name': 'incoming', 'type': 'BOOLEAN', 'mode': 'NULLABLE'}, {'name': 'registered', 'type': 'BOOLEAN', 'mode': 'NULLABLE'}, {'name': 'count', 'type': 'INTEGER', 'mode': 'NULLABLE'}]}. Additional parameters: {}. Source format: NEWLINE_DELIMITED_JSON\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_ebdf7a9f317345dd9af236a2dc818441_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0'\n",
      " location: 'US'\n",
      " projectId: 'data604-project-g3'>\n",
      " bq show -j --format=prettyjson --project_id=data604-project-g3 beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_ebdf7a9f317345dd9af236a2dc818441_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Job data604-project-g3:US.beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_ebdf7a9f317345dd9af236a2dc818441_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0 status: RUNNING\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Job data604-project-g3:US.beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_ebdf7a9f317345dd9af236a2dc818441_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0 status: DONE\n",
      "INFO:apache_beam.runners.worker.statecache:Creating state cache with size 104857600\n",
      "INFO:apache_beam.io.gcp.bigquery_file_loads:Load job has 1 files. Job name is beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_914fb6b89d254c15a06ccd7b0e03af0c_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0.\n",
      "INFO:apache_beam.io.gcp.bigquery_file_loads:Triggering job beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_914fb6b89d254c15a06ccd7b0e03af0c_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0 to load data to BigQuery table <TableReference\n",
      " datasetId: 'Footprint_data'\n",
      " projectId: 'data604-project-g3'\n",
      " tableId: 'calls'>.Schema: {'fields': [{'name': 'user_id', 'type': 'STRING', 'mode': 'NULLABLE'}, {'name': 'phone_number', 'type': 'STRING', 'mode': 'NULLABLE'}, {'name': 'incoming', 'type': 'BOOLEAN', 'mode': 'NULLABLE'}, {'name': 'registered', 'type': 'BOOLEAN', 'mode': 'NULLABLE'}, {'name': 'count', 'type': 'INTEGER', 'mode': 'NULLABLE'}]}. Additional parameters: {}. Source format: NEWLINE_DELIMITED_JSON\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_914fb6b89d254c15a06ccd7b0e03af0c_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0'\n",
      " location: 'US'\n",
      " projectId: 'data604-project-g3'>\n",
      " bq show -j --format=prettyjson --project_id=data604-project-g3 beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_914fb6b89d254c15a06ccd7b0e03af0c_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Job data604-project-g3:US.beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_914fb6b89d254c15a06ccd7b0e03af0c_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0 status: RUNNING\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Job data604-project-g3:US.beam_bq_job_LOAD_AUTOMATIC_JOB_NAME_LOAD_STEP_914fb6b89d254c15a06ccd7b0e03af0c_236eb1a8c2973147fb3da8f1cd2ff4ec_pane0_partition0 status: DONE\n"
     ]
    }
   ],
   "source": [
    "def define_key(element):\n",
    "    import json\n",
    "    del element['time']\n",
    "    return (json.dumps(element), element)\n",
    "\n",
    "def expand(element):\n",
    "    import json\n",
    "    key, value = element\n",
    "    dictionary = json.loads(key)\n",
    "    dictionary['count'] = value\n",
    "    return dictionary\n",
    "\n",
    "def parse_csv(line):\n",
    "    import csv\n",
    "    return next(csv.reader([line]))\n",
    "\n",
    "with beam.Pipeline(runner='DirectRunner') as pipeline:\n",
    "    lines = pipeline | beam.io.ReadFromText('gs://data604-project-g3-data/calls.json')\n",
    "    parsed_lines = lines | beam.Map(json.loads)\n",
    "    keyed_lines = parsed_lines | \"Define_Key\" >> beam.Map(define_key)\n",
    "    counted = keyed_lines | 'Count elements per key' >> beam.combiners.Count.PerKey()\n",
    "    result = counted | 'Turn key back to content' >> beam.Map(expand)\n",
    "    result | \"Write To BigQuery\" >> WriteToBigQuery(\n",
    "        table=table, schema=table_schema,\n",
    "        custom_gcs_temp_location = \"gs://data604-project-g3-data/.cache\",\n",
    "        create_disposition=BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "        write_disposition=BigQueryDisposition.WRITE_APPEND\n",
    "    )\n",
    "    result = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6cd8d89-6931-4b1a-949c-1383baafd79d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fdf2cdb8eb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0cb93-9e96-425e-8694-98af8d14bb31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "apache-beam-2.60.0",
   "name": ".m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
